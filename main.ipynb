{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary keys are:\n",
    "\n",
    "- `id`: integer, id #\n",
    "- `image_id`: integer, image id #\n",
    "- `category_id`: 1 for penguin, 2 for turtle\n",
    "- `bbox`: list of integers representing the bounding box coordinates in Pascal VOC format [xmin, ymin, xmax, ymax]\n",
    "- `area`: integer representing area of bounding box.\n",
    "- `segmentation`: empty list; add segmentation masks if you'd like!\n",
    "- `iscrowd`: integer 0 or 1; whether the instance is a crowd or individual. Not relevant to this particular use case, but is a necessary key for some models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform COCO annotations to YOLO format\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1.0 / size[0]\n",
    "    dh = 1.0 / size[1]\n",
    "    x = (box[0] + box[2] / 2.0) * dw\n",
    "    y = (box[1] + box[3] / 2.0) * dh\n",
    "    w = box[2] * dw\n",
    "    h = box[3] * dh\n",
    "    return [x, y, w, h]\n",
    "\n",
    "\n",
    "def convert_annotation(image_info, output_path):\n",
    "    image_id = str(image_info[\"image_id\"]).zfill(3)\n",
    "    with open(os.path.join(output_path, f\"image_id_{image_id}.txt\"), \"w\") as outfile:\n",
    "        box = convert((640, 640), image_info[\"bbox\"])\n",
    "        outfile.write(\n",
    "            f\"{image_info['category_id']-1} {' '.join([str(a) for a in box])}\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "def coco_to_yolo(coco_annotation_file, output_path):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    with open(coco_annotation_file) as file:\n",
    "        data = json.load(file)\n",
    "        for img in data:\n",
    "            convert_annotation(img, output_path)\n",
    "\n",
    "\n",
    "coco_to_yolo(\"datasets/train_annotations.json\", \"datasets/labels/train/\")\n",
    "coco_to_yolo(\"datasets/valid_annotations.json\", \"datasets/labels/valid/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Preprocessing\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocessing(input_path: str, output_path: str):\n",
    "    \n",
    "    for file_name in os.listdir(input_path):\n",
    "        original_img = cv2.imread(os.path.join(input_path, file_name))\n",
    "        \n",
    "        img = original_img.astype(np.float32)\n",
    "        \n",
    "        # Data Augmentation: Adding Gaussian Noise\n",
    "        img += np.random.normal(0, 20, img.shape)\n",
    "        \n",
    "        # save image\n",
    "        img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(output_path, file_name), img)\n",
    "        \n",
    "        \n",
    "        # flip image\n",
    "        img = cv2.flip(img, 1)\n",
    "        name = file_name.split(\".\")[0] + \"_flip.jpg\"\n",
    "        cv2.imwrite(os.path.join(output_path, name), img)\n",
    "        \n",
    "        # modify label\n",
    "        name = file_name.split(\".\")[0] + \"_flip.txt\"\n",
    "        with open(os.path.join(\"datasets/labels/train_preprocessed\", name), \"w\") as f:\n",
    "            with open(os.path.join(\"datasets/labels/train\", file_name.split(\".\")[0] + \".txt\"), \"r\") as f2:\n",
    "                for line in f2:\n",
    "                    line = line.split(\" \")\n",
    "                    line[1] = str(1 - float(line[1]))\n",
    "                    f.write(\" \".join(line))\n",
    "        \n",
    "        \n",
    "        # # show changed image and the original image\n",
    "        # cv2.imshow(\"original\", original_img)\n",
    "        # cv2.imshow(\"changed\", img)\n",
    "        \n",
    "        # if cv2.waitKey(0) == ord('q'):\n",
    "        #     cv2.destroyAllWindows()\n",
    "        #     break\n",
    "\n",
    "\n",
    "\n",
    "preprocessing(\"datasets/images/train\", \"datasets/images/train_preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training YOLOv8n on animal dataset\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"datasets/weights/yolov8n.pt\")\n",
    "\n",
    "model.train(data=\"animal.yaml\", imgsz=640, epochs=100, batch=8, workers=4, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts on all images in datasets/images/valid\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"runs/detect/train3/weights/best.pt\")\n",
    "\n",
    "for file in os.listdir(\"datasets/images/valid\"):\n",
    "    model.predict(\n",
    "        os.path.join(\"datasets/images/valid\", file),\n",
    "        conf=0.8,\n",
    "        save=True,\n",
    "        save_conf=True,\n",
    "        augment=True,\n",
    "        # visualize=True,\n",
    "        device=0,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP9517-xElOVYfG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
